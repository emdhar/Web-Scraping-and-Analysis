{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66f84258-3fe0-4ea6-bac6-6759f08c3a33",
   "metadata": {},
   "source": [
    "Student id: 24206493"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3024cef-3679-44ac-b68d-337df22c68c6",
   "metadata": {},
   "source": [
    "### Task 1: Data Collection\n",
    "\n",
    "Choose one of the four data sources listed here:\n",
    "http://mlg.ucd.ie/modules/python/assignment1\n",
    "In your first notebook, apply web scraping in Python to collect and parse all of the data from your chosen source. \n",
    "Save the collected data in an appropriate format for subsequent analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca5263-bc27-4437-98e8-48ac237bd24d",
   "metadata": {},
   "source": [
    "For this assigment, I am using the Blue Motive Cars website that provides listings for second-hand car sales in Ireland on this link: http://mlg.ucd.ie/modules/python/assignment1/cars/index.html. I start by importing urllib and beautifulSoup libraries to fetch and read the response from the url link provided and then to parse the HTML response respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "318ce905-5f24-49c6-a633-9c99c237f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import bs4\n",
    "\n",
    "url = \"http://mlg.ucd.ie/modules/python/assignment1/cars/index.html\"\n",
    "response = urllib.request.urlopen(url)\n",
    "bluecars = response.read().decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5b66a8-9b4b-41c2-a9cb-55c95aa82c80",
   "metadata": {},
   "source": [
    "Create a BeautifulSoup object which contains the structure of the HTML page using HTML parser feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52907f0b-572e-40a2-91cf-5d769b23fc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "<meta content=\"noindex\" name=\"robots\"/>\n",
      "<meta content=\"Content on this site is posted for teaching purposes only. Original data is from theguardian.com\" name=\"description\"/>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
      "<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
      "<title>Car Sale Records</title>\n",
      "<link href=\"http://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css\" rel=\"stylesheet\" target=\"_blank\"/>\n",
      "<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js\"></script>\n",
      "<script src=\"http://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js\"></script>\n",
      "<link href=\"style.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "</head>\n",
      "<body>\n",
      "<div class=\"container mtb\">\n",
      "<div class=\"logo\">\n",
      "<a href=\"index.html\"><img alt=\"Property Price Register\" class=\"logo\" src=\"logo.png\"/></a>\n",
      "</div>\n",
      "<div class=\"row instructions\">\n",
      "<div class=\"col-md-12\" id=\"content\">\n",
      "<p ;=\"\" style=\"font-size: 105%\">\n",
      "                This website provides listings for second-hand car sales, with the following information provided for each sale:\n",
      "              </p>\n",
      "<ul>\n",
      "<li> The make and model of the car.</li>\n",
      "<li> The date when the car was sold.</li>\n",
      "<li> The price at which the car was sold, in Euros.</li>\n",
      "<li> The year the car was manufactured.</li>\n",
      "<li> The total distance the car has traveled, in miles.</li>\n",
      "<li> The classification type of the car, such as hatchback or SUV.</li>\n",
      "<li> The type of transmission the car has, such as manual or automatic.</li>\n",
      "<li> The type of fuel the car uses, such as petrol or diesel.</li>\n",
      "<li> The county in Ireland where the car was sold.</li>\n",
      "<li> Additional details about the car's features and history.</li>\n",
      "</ul>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"row\">\n",
      "<div class=\"col-md-12\">\n",
      "\t\t\t\tCar sales are divided by make, as follows:\n",
      "\t\t\t</div>\n",
      "<div class=\"col-md-12\" id=\"content\">\n",
      "<div>\n",
      "<h4><a href=\"Audi-page01.html\">Make: Audi</a></h4>\n",
      "\t\t\t\t\tList of all car sales for Audi\n",
      "\t\t\t\t\t</div>\n",
      "<div>\n",
      "<h4><a href=\"BMW-page01.html\">Make: BMW</a></h4>\n",
      "\t\t\t\t\tList of all car sales for BMW\n",
      "\t\t\t\t\t</div>\n",
      "<div>\n",
      "<h4><a href=\"Mercedes-Benz-page01.html\">Make: Mercedes-Benz</a></h4>\n",
      "\t\t\t\t\tList of all car sales for Mercedes-Benz\n",
      "\t\t\t\t\t</div>\n",
      "<div>\n",
      "<h4><a href=\"Volkswagen-page01.html\">Make: Volkswagen</a></h4>\n",
      "\t\t\t\t\tList of all car sales for Volkswagen\n",
      "\t\t\t\t\t</div>\n",
      "<br/>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"footer\">\n",
      "            Content on this site is posted for teaching purposes only. \n",
      "        </div>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "soup = bs4.BeautifulSoup(bluecars, 'html.parser') \n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219f6fc3-4d49-496a-8938-1224d037c46a",
   "metadata": {},
   "source": [
    "Create an explicit function, getlinks() that takes BS obj as prameter and does link gathering from the current page whenever called. This will be important later when we will have to gather the 20 odd links for one cartype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59e19fcd-13f4-4e16-b1d8-ea303ebb0583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlinks(BSobject):\n",
    "    links = BSobject.find_all(\"a\")\n",
    "    baseurl = \"http://mlg.ucd.ie/modules/python/assignment1/cars/\"\n",
    "    list = \"\"\n",
    "    list1 = []\n",
    "    for link in links:\n",
    "        car_html = link.get(\"href\")\n",
    "        list = baseurl + car_html\n",
    "        list1.append(list)\n",
    "    list1.pop(0)\n",
    "    return list1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47710ca-27f2-4433-bb70-435276e5efb8",
   "metadata": {},
   "source": [
    "The gettext() function takes 2 parameters, the extracted \"li\" list and a dummy list for storing the output dictionaries.\n",
    "I created this function in hindsight when I saw that this part of getting text from the \"li\" list was getting duplicated mainly to keep the code crisp. \n",
    "Additionally, I have added text.strip to avoid wasting time on cleaning the text feature-wise for the analysis. This was added after I started analysis in Notebook 2 and got caught up with spaces around these values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "827a924c-b18b-4ad0-9296-bcdbd754b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettext(modelname, temp_list):\n",
    "    for j in modelname:\n",
    "        dict_car = {}\n",
    "        Make = j.find(\"span\", {\"class\" : \"make-model\"}).text.strip()    # Make-model is not in a <td> tag but in a separate span class in the <li> tag so the treatment is different for it\n",
    "        dict_car[\"Make-Model\"] = Make\n",
    "        td_list = j.find_all(\"td\")\n",
    "        for i, td in enumerate(td_list):\n",
    "            if td.text == 'Date of Sale:':\n",
    "                dict_car[\"Date of Sale\"] = td_list[i+1].text.strip() \n",
    "            if td.text == 'Sale Price:':\n",
    "                dict_car[\"Sale Price\"] = td_list[i+1].text.strip() \n",
    "            if td.text == 'Year:':\n",
    "                dict_car[\"Year\"] = td_list[i+1].text.strip() \n",
    "            if td.text == 'Mileage:':\n",
    "                dict_car[\"Mileage\"] = td_list[i+1].text.strip() \n",
    "            if td.text == 'Classification:':\n",
    "                dict_car[\"Classification\"] = td_list[i+1].text.strip() \n",
    "            if td.text == 'Transmission:':\n",
    "                dict_car[\"Transmission\"] = td_list[i+1].text.strip() \n",
    "            if td.text == 'Fuel Type:':\n",
    "                dict_car[\"Fuel Type\"] = td_list[i+1].text.strip() \n",
    "            if td.text == 'Description:':\n",
    "                dict_car[\"Description\"] = td_list[i+1].text.strip() \n",
    "            if td.text == 'Sale Location:':\n",
    "                dict_car[\"Sale Location\"] = td_list[i+1].text.strip() \n",
    "        temp_list.append(dict_car)       \n",
    "    return temp_list "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b75f5f-3d42-4afd-93de-c03a4c2be6b3",
   "metadata": {},
   "source": [
    "#### The list \"main_list\" has the links of 4 car-types fetched from the BlueCars main webpage using getlinks() function. My strategy is three-fold: \n",
    "\n",
    "1. Use getlinks() to get all the links on pages\n",
    "2. Use gettext() to get all the car model details on the page and put it in a dictionary which goes into a list. \n",
    "For each cartype, there will be 4 lists of dictionaries in the final list (final_retriever).\n",
    "3. Export the text in a CSV file using csv.DictWriter for further data preparation and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb51bf3a-57fa-46c7-b34b-bae3bd751518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384 396 593 327\n"
     ]
    }
   ],
   "source": [
    "main_list = getlinks(soup)\n",
    "final_retriever = []  # this is our main guy here. It will have all the 4 lists of dictionaries\n",
    "\n",
    "for mainlink in main_list:\n",
    "    response = urllib.request.urlopen(mainlink)\n",
    "    Cars = response.read().decode()\n",
    "    cartype_soup = bs4.BeautifulSoup(Cars, 'html.parser')\n",
    "    #print(cartype_soup) # to check if we got the html data\n",
    "    list2 = getlinks(cartype_soup)\n",
    "    list2.pop(-1)    # this list is crucial as it gets all the links from the first page itself. It saves time as we will see in our next for loop.\n",
    "    #print(list2)    #check\n",
    "    list = []\n",
    "    modelname = cartype_soup.find_all(\"li\")  # modelname has all the <li> tags as a list in it and the <td> tag that has all the relavent data for us is a child of the <li> tag.\n",
    "    list = gettext(modelname, list)\n",
    "    for j in list2:\n",
    "        response = urllib.request.urlopen(j)\n",
    "        Cars = response.read().decode()\n",
    "        cartype_soup = bs4.BeautifulSoup(Cars, 'html.parser')\n",
    "        modelname = cartype_soup.find_all(\"li\")\n",
    "        list = gettext(modelname, list)\n",
    "        #print(list)   #check\n",
    "    final_retriever.append(list)\n",
    "\n",
    "#checking if we got all the data\n",
    "print(len(final_retriever[0]), len(final_retriever[1]), len(final_retriever[2]), len(final_retriever[3]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd6f71e-7356-472d-b1b0-6531a8d76d5a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "CSV library is imported to create and write into a new csv file for writing all the data fetched in the list, final_retriever under relavent headers. I use two for loops, one for accessing the first list that has one type of car-type and then another one to access the dictionaries of that car-type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7eaf769f-92c3-4b7b-bcdb-5336df621b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "fout = open('final_retriever.csv', 'w')\n",
    "fields = ['Make-Model', 'Date of Sale', 'Sale Price', 'Year', 'Mileage', 'Classification', 'Transmission', 'Fuel Type', 'Description', 'Sale Location' ]\n",
    "writer = csv.DictWriter(fout, fieldnames = fields)\n",
    "writer.writeheader()\n",
    "for x in final_retriever:\n",
    "    for m in x:\n",
    "        writer.writerow(m)\n",
    "\n",
    "fout.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
